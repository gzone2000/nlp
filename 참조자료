o word2vec 관련 이론 정리
https://shuuki4.wordpress.com/2016/01/27/word2vec-%EA%B4%80%EB%A0%A8-%EC%9D%B4%EB%A1%A0-%EC%A0%95%EB%A6%AC/

o Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)
https://nlpinkorean.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/

o The Illustrated Transformer
https://nlpinkorean.github.io/illustrated-transformer/

o 월간 자연어 처리
https://www.facebook.com/monthly.nlp/

o Korean Corpora Archives
https://github.com/ko-nlp/Korpora

o 2주 간의 KoELECTRA 개발기 
https://monologg.kr/2020/05/02/koelectra-part1/

o [Paper Review] Transformer to T5 (XLNet, RoBERTa, MASS, BART, MT-DNN,T5)
http://dsba.korea.ac.kr/seminar/?mod=document&uid=247

o 2주 간의 KoELECTRA 개발기 - 1부
https://monologg.kr/2020/05/02/koelectra-part1/

o BERT 온라인 강의
https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=164

o Transformer
https://www.youtube.com/watch?v=mxGCEWOxfe8

o Transformer & BERT
https://www.youtube.com/watch?v=xhY7m8QVKjo

o 김동화 - Transformer & BERT
https://www.youtube.com/watch?v=xhY7m8QVKjo
